[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "",
    "text": "Have you ever been stuck at an airport for multiple hours at a time because of a delay? Or have you missed a flight because one of your previous flights was delayed? Knowing which airport is more likely to be delayed can be extremely helpful when booking a vacation. This report will give some valuable information about which airports you might want to pick on your flight path, and which ones are more likely to have delays.\n\n\nRead and format project data\n# Include and execute your code here\nurl_flights = 'https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json'\nflights = pd.read_json(url_flights)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#airport-troubles",
    "href": "Projects/project2.html#airport-troubles",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "",
    "text": "Have you ever been stuck at an airport for multiple hours at a time because of a delay? Or have you missed a flight because one of your previous flights was delayed? Knowing which airport is more likely to be delayed can be extremely helpful when booking a vacation. This report will give some valuable information about which airports you might want to pick on your flight path, and which ones are more likely to have delays.\n\n\nRead and format project data\n# Include and execute your code here\nurl_flights = 'https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json'\nflights = pd.read_json(url_flights)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#data-cleansing-and-organizing",
    "href": "Projects/project2.html#data-cleansing-and-organizing",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "Data Cleansing and Organizing",
    "text": "Data Cleansing and Organizing\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value\nThere were 5 main problems with the data set. A spelling error for the month February, and different types of inconsistancies with missing values. For the whole data set, whenever there is a 1500+ as a value, I replaced it with just 1500. I could have replaced it with the mean, but I considered the possibility of the system not allowing values over 1500, so the values that belong in those spots, could possibly just be outliers, so I kept them as 1500. I replaced the -999s as NaNs because there is no way to tell what that value is supposed to be. There were blanks in the airport name coloumn, so I replaced the blanks with the correct airport name according to the code. \n\n\nRead and format data\n# Include and execute your code here\n## Repalce 1500+ with 1500\nflights.replace('1500+', 1500, inplace = True)\n\n## This coloumn was all strings which will cause problems later, so I changed it to integers\nflights['num_of_delays_carrier'] = flights['num_of_delays_carrier'].astype(int)\n\n## Replace 'Febuary' with 'February'\nflights.replace('Febuary', 'February', inplace = True)\n\n## Replace -999 with NaN\nflights.replace(-999, np.nan, inplace = True)\n\n## Replace blank for airport code IAD with correct name\nflights['airport_name'].replace('', 'Washington, DC: Washington Dulles International', inplace = True)\n\n## Replace n/a in coloum month with np.nan\nflights['month'].replace('n/a', np.nan, inplace = True)\n\n## Trying to change the year to an integer, doesn't work\n# flights['year'].astype(int)\n\nflights.iloc[0:10]\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928.0\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\nWashington, DC: Washington Dulles International\nJanuary\n2005.0\n12381\n414\n1058.0\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255.0\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680.0\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n\n\n5\nSFO\nSan Francisco, CA: San Francisco International\nJanuary\n2005.0\n10274\n798\n733.0\n1166\n7\n114\n2816\n41570.0\n47705\n60380.0\n247\n7373\n157275\n\n\n6\nSLC\nSalt Lake City, UT: Salt Lake City International\nJanuary\n2005.0\n12000\n817\n564.0\n864\n13\n270\n2525\n36252.0\n30557\n35977.0\n327\n27219\n130332\n\n\n7\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nFebruary\n2005.0\n33702\n1288\nNaN\n6104\n2\n399\n9195\n86876.0\n86698\n321969.0\n36\n31944\n527523\n\n\n8\nDEN\nDenver, CO: Denver International\nFebruary\n2005.0\n11480\n729\n432.0\n581\n4\n42\n1788\n33205.0\n26228\n16864.0\n271\n2781\n79349\n\n\n9\nIAD\nWashington, DC: Washington Dulles International\nFebruary\n2005.0\n10042\n284\n631.0\n691\n4\n28\n1639\n15573.0\n39840\nNaN\n169\n1359\n78878",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#what-airport-might-have-the-worst-delays",
    "href": "Projects/project2.html#what-airport-might-have-the-worst-delays",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "What Airport Might Have The Worst Delays?",
    "text": "What Airport Might Have The Worst Delays?\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nThere are 7 unique airports in this data set. Based off of the proportion of delayed flights, San Francisco has the highest proportion of delayed flights. Atlanta has the most delayed flights, but it also has the highest number of flights. Proportion is better to go off of because it more accurately represents how often there is a delayed flight. So by using proportion, we can see that it is San Francisco that can be classified as the airport with the worrst delays.\nThe table below shows information for each airport. It shows the airport name, the total amount of flights, the number of total delays, the proportion of delayed flights, and the average delay in hours.\n\n\nShow the code\n## Creates a dictionary that is later used to fill all Nas with the mean of the given coloumn\nmean_fill = {\n    'num_of_delays_carrier': flights['num_of_delays_carrier'].mean(),\n    'num_of_delays_late_aircraft': flights['num_of_delays_late_aircraft'].mean(),\n    'minutes_delayed_carrier': flights['minutes_delayed_carrier'].mean(),\n    'minutes_delayed_nas': flights['minutes_delayed_nas'].mean(),\n}\n## This fills Nas using the dictionary\nflights_filled = flights.fillna(value=mean_fill).round(0)\n## This is forward filling the month coloumn when there is an Na\nflights_filled.month.fillna(method = 'ffill', inplace = True)\n## Forward filling year so there are no NaNs\nflights_filled.year.fillna(method = 'ffill', inplace = True)\n\n## Doesn't work correctly, does not group by the airport name\n#  summary_stats = (flights_filled.assign(\n#     prop_delayed_flights = lambda x: x.num_of_delays_total / x.num_of_flights_total,\n#     ave_delay_time_hours = lambda x: (x.minutes_delayed_total /60).mean()).filter(['airport_code','airport_name', 'num_of_flights_total', 'num_of_delays_total', 'prop_delayed_flights', 'ave_delay_time_hours']))\n\nsummary_stats = flights_filled.groupby('airport_name').agg({\n    'num_of_flights_total': 'sum',\n    'num_of_delays_total': 'sum',\n    'minutes_delayed_total': 'sum'\n}).reset_index()\nsummary_stats['prop_delayed_flights'] = summary_stats['num_of_delays_total'] / summary_stats['num_of_flights_total']\nsummary_stats['ave_delay_time_hours'] = summary_stats['minutes_delayed_total'] / (60 * summary_stats['num_of_flights_total'])\n\nsummary_stats\n\n\n\n\n\n\n\n\n\nairport_name\nnum_of_flights_total\nnum_of_delays_total\nminutes_delayed_total\nprop_delayed_flights\nave_delay_time_hours\n\n\n\n\n0\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\n4235114\n870910\n52114971\n0.205640\n0.205091\n\n\n1\nChicago, IL: Chicago O'Hare International\n3400032\n773122\n52165135\n0.227387\n0.255709\n\n\n2\nDenver, CO: Denver International\n2323376\n439964\n23660463\n0.189364\n0.169728\n\n\n3\nSalt Lake City, UT: Salt Lake City International\n1293072\n190733\n9460901\n0.147504\n0.121943\n\n\n4\nSan Diego, CA: San Diego International\n870161\n167747\n7922432\n0.192777\n0.151743\n\n\n5\nSan Francisco, CA: San Francisco International\n1565257\n408631\n25488636\n0.261063\n0.271400\n\n\n6\nWashington, DC: Washington Dulles International\n1658359\n325043\n19934488\n0.196003\n0.200344\n\n\n\n\n\n\n\n\n\nShow the code\nfig1 = px.bar(\n    summary_stats,\n    x = 'airport_name',\n    y = 'prop_delayed_flights',\n    color = \"airport_name\"\n)\n\nfig1.update_xaxes(\n  title_text = 'Airport Name'\n)\n\nfig1.update_yaxes(\n  title_text = 'Proportion of Delayed Flights'\n)\n\nfig1\n\n\n                                                \n\n\n_The graph above shows another visual of the data. This shows that San Francisco has the highest proportion of delayed flights, and this could be because of weather, the high population of San Francisco, and many other factors.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#what-time-of-year-should-you-go-on-vacation",
    "href": "Projects/project2.html#what-time-of-year-should-you-go-on-vacation",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "What Time Of Year Should You Go On Vacation?",
    "text": "What Time Of Year Should You Go On Vacation?\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nBased off of the graph below, September is the month that has the best delay rate. You could say that the fall months as a whole are the best months to fly, because they are all pretty similar. The month you would expect the most amount of delays is December, and most likely because it is the holiday season, and there are so many people moving around the country.\n\n\nShow the code\n# Find the total number of delays per month:\nmonthly_delay_totals = flights_filled.groupby('month')['num_of_delays_total'].sum()\n\n# Find the total amount of flights per month:\nmonthly_flight_totals = flights_filled.groupby('month')['num_of_flights_total'].sum()\n\n#Proportion of flights delayed per month\ndelay_rate_monthly = monthly_delay_totals / monthly_flight_totals\n\n# Making a new data frame so I can build a plot\ndelaydf = pd.DataFrame({'Month': delay_rate_monthly.index, 'Delay Rate': delay_rate_monthly.values})\n\n# Creating a list of correct month order\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\nfig2 = px.bar(\n  delaydf,\n  x = 'Month',\n  y = 'Delay Rate',\n  color = 'Month',\n  title = \"Delay Rate Based on Month\"\n)\n\n# Add horizontal line to show lowest month\nfig2.add_hline(\n  y = delaydf['Delay Rate'].min(),\n  line_dash = 'dot'\n)\n\n# Updating x-axis to correct month order\nfig2.update_xaxes(\n  categoryorder = 'array', categoryarray = month_order\n)\n\nfig2\n\n\n                                                \n\n\nThe black dotted line is perpendicular to the lowest delay rate, showing that it is september. You can see how much lower it is than some months like June and December, and how there are similar months like april, october, and november.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#different-types-of-weather-delays",
    "href": "Projects/project2.html#different-types-of-weather-delays",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "Different Types of Weather Delays",
    "text": "Different Types of Weather Delays\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\n100% of delayed flights in the Weather category are due to weather\n30% of all delayed flights in the Late-Arriving category are due to weather.\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%.\nUsing this new data frame we can better see how the weather affects the delays at each airport. It will show which airports are delayed because of things like security and how busy each airport is. \n\n\nShow the code\nweather = (flights_filled.assign(\n    severe = flights_filled.num_of_delays_weather, # no missing\n    # Replaces any -999 in data with NaN\n    nodla_nona = lambda x: (x.num_of_delays_late_aircraft\n        .replace(-999, np.nan)), #missing is -999\n    mild_late = lambda x: x.nodla_nona.fillna(x.nodla_nona.mean())*0.3,\n    # Numpy \n    mild = np.where(\n        flights_filled.month.isin(['April', 'May', 'June', 'July', 'August']), \n            flights_filled.num_of_delays_nas*0.4,\n            flights_filled.num_of_delays_nas*0.65),\n   # The lambda x calls self, so it is calling the weather, then going through .severe\n    weather = lambda x: x.severe + x.mild_late + x.mild,\n    proportion_weather_delay = lambda x: x.weather / x.num_of_delays_total,\n    proportion_weather_total = lambda x:  x.weather / x.num_of_flights_total)\n    .filter(['airport_code','month','year', 'severe','mild', 'mild_late',\n    'weather', 'proportion_weather_total', \n    'proportion_weather_delay', 'num_of_flights_total', 'num_of_delays_total']))\nweather.head()\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_late\nweather\nproportion_weather_total\nproportion_weather_delay\nnum_of_flights_total\nnum_of_delays_total\n\n\n\n\n0\nATL\nJanuary\n2005.0\n448\n2988.70\n332.7\n3769.40\n0.107550\n0.451155\n35048\n8355\n\n\n1\nDEN\nJanuary\n2005.0\n233\n607.75\n278.4\n1119.15\n0.088212\n0.354948\n12687\n3153\n\n\n2\nIAD\nJanuary\n2005.0\n61\n581.75\n317.4\n960.15\n0.077550\n0.395123\n12381\n2430\n\n\n3\nORD\nJanuary\n2005.0\n306\n3519.75\n676.5\n4502.25\n0.159688\n0.490548\n28194\n9178\n\n\n4\nSAN\nJanuary\n2005.0\n56\n414.70\n204.0\n674.70\n0.092640\n0.345645\n7283\n1952",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#what-airport-has-the-worst-weather",
    "href": "Projects/project2.html#what-airport-has-the-worst-weather",
    "title": "Client Report - [Flight Trends and Best Seasons to Fly]",
    "section": "What Airport Has the Worst Weather?",
    "text": "What Airport Has the Worst Weather?\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nThe plot below shows that San Francisco has the highest proportion of weather delays compared to the other airports in the data set. This could be for a number of reasons, most likely because San Francisco is known for it’s rainy seasons, which could delay flights. On the contrary, Salt lake has the lowest proportion of weather delays, most likely due to Salt Lakes dryer atmosphere. Knowing weather patterns and the probability of weather delays at specific airports will help you get to your destination safe and on time.\n\n\nShow the code\n# Grouping weather to find total weather delays by airport code\nweather_totals_by_aircode = weather.groupby('airport_code')['weather'].sum()\ntotal_flights_by_aircode = weather.groupby('airport_code')['num_of_flights_total'].sum()\n\nweather_prop_by_aircode = weather_totals_by_aircode / total_flights_by_aircode\n\nweatherdf = pd.DataFrame({'airport_code': weather_prop_by_aircode.index, \n                          'proportion_weather_total': weather_prop_by_aircode.values})\n\nfig3 = px.bar(\n  weatherdf,\n  x='airport_code',\n  y='proportion_weather_total',\n  color = 'airport_code',\n  title = 'Proportion of Delays Due to Weather by Airport',\n  labels = {'proportion_weather_total': 'Proportion Weather Total', 'airport_code': 'Airport Code'}\n)\n\nfig3\n\n\n                                                \n\n\nIf you remember from earlier in the report, it was mentioned that San Francisco also had the highest proportion of delays overall.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "",
    "text": "Have you ever wondered why certain names become so popular at specific times in history? Countless factors can influence the usage of names, ranging from movies and celebrities to global events and shifts in social structure. In this report, you will discover intriguing information about how certain names change over time and explore events that may have an impact on their usage.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#name-trends-causes-and-effects",
    "href": "Projects/project1.html#name-trends-causes-and-effects",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "",
    "text": "Have you ever wondered why certain names become so popular at specific times in history? Countless factors can influence the usage of names, ranging from movies and celebrities to global events and shifts in social structure. In this report, you will discover intriguing information about how certain names change over time and explore events that may have an impact on their usage.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#the-usage-of-my-name-over-time",
    "href": "Projects/project1.html#the-usage-of-my-name-over-time",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "The Usage Of My Name Over Time",
    "text": "The Usage Of My Name Over Time\nHow does your name at your birth year compare to its use historically?\nMy name, Joseph, has been pretty popular over the last 100 years. There were 2 peaks in the last hundred years, one of them was during the 50s, and one was during the 90s. The trend of the name Joseph started going down in the 2000s, and my birth year is the beginning of the trend going down. It will be less probable for a person named Joseph to be younger than me than it is for someone named Joseph to be older than me.\n\n\nShow the code\n#Build the Plot\nfig1 = px.line(\n    df.query('name == \"Joseph\"'),\n    x = 'year',\n    y = 'Total',\n    title = \"The Usage Of The Name Joseph Over Time\"\n)\n#Add the Vertical line to mark my birth year\nfig1.add_vline(\n    x = 2005,\n    line_dash = 'dot',\n    line_color = 'black'\n)\n#Fix the x axis name, and resize the title\nfig1.update_layout(\n    xaxis_title = \"Year\",\n    title_font = dict(size = 20),\n)\n#Makes a dot on the page\n# fig1.add_scatter(\n#     x = df.query('name == \"Joseph\"')[df[\"year\"] == 2005][\"year\"],\n#     y = df.query('name == \"Joseph\"')[df[\"year\"] == 2005][\"Total\"]\n# )\n\n# fig1\n\n\n                                                \n\n\nThe vertical black line on the graph marks my birth year. As you can see, there is a trend downward after my birth year",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#how-old-should-you-expect-brittany-to-be",
    "href": "Projects/project1.html#how-old-should-you-expect-brittany-to-be",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "How Old Should You Expect Brittany To Be?",
    "text": "How Old Should You Expect Brittany To Be?\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nThe name Brittney peaked in the year 1990, and the average birth year for all people named Brittany is 1991. This means that there is a high probability that the person on the phone is around the age 33. To be safe, you could assume that the person is between the ages 30-37. It would much less likely for the person to be around my age, 19, because the graph looks like the year 2005 is about 3 standard deviations away from the mean. As well as for over the age 44, because that seems to be close to the 3rd standard deviation as well. \n\n\nShow the code\n#Making the bar plot\nfig2 = px.bar(\n    df.query('name == \"Brittany\"'),\n    x = 'year',\n    y = 'Total',\n    title = 'The Name Brittany Over Time'\n)\n#Renaming the x axis so there is not a lower case, and changing title size\nfig2.update_layout(\n    xaxis_title = \"Year\",\n    title_font = dict(size = 20),\n)\n#Updating the range of y axis to make more room for the arrows\nfig2.update_yaxes(\n    range = [0, 40000]\n)\n#Vertical line at average year\nfig2.add_vline(\n    x = 1991,\n    line_dash = 'dot',\n    line_color = 'black'\n)\n#Arrow pointing to peak\nfig2.add_annotation(\n    x=1990, \n    y=max(df.query('name == \"Brittany\"')['Total']), \n    text=\"Peak\",\n    showarrow=True,\n    arrowhead=1,\n    ax=-40,  \n    ay=-30,\n    arrowcolor=\"red\",\n    font= dict(color=\"red\")\n)\n#Arrow pointing to average year vertical line\nfig2.add_annotation(\n    x=1991, \n    y=35000, \n    text=\"Average Year\",\n    showarrow=True,\n    arrowhead=1,\n    ax=40,  \n    ay=-20,\n    arrowcolor=\"black\",\n    font= dict(color=\"black\")\n)\n#Computing the average year that the name Brittany was used\ntotal_occurrences = df.query(\"name == 'Brittany'\")['Total'].sum()\naverage_year = (df.query(\"name == 'Brittany'\")['Total'] * df.query(\"name == 'Brittany'\")['year']).sum() / total_occurrences\nage = 2024 - average_year\nprint(f\"Average Age of All People Named Brittney: {age:.0f}\")\n\nfig2\n\n\nAverage Age of All People Named Brittney: 33\n\n\n                                                \n\n\nThe graph provides a label for the peak year, and the average year. You can see that the graph follows a normal distribution, so it is more likely for the person named Brittany to be around 33 years old considering that is the average.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#how-did-religious-names-trend-over-time",
    "href": "Projects/project1.html#how-did-religious-names-trend-over-time",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "How Did Religious Names Trend Over Time?",
    "text": "How Did Religious Names Trend Over Time?\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nIn all four of the names, there is an upward trend around he year 1950, immediately followed by a gradual decrease for the names Martha, Paul, and Peter, but a very steep decrease for the name Mary. My guess is that something happened socially in the year 1950 that made religious names less popular. It could be anything from the baby boom to the Cold War that caused a decrease in religious names.\n\n\nShow the code\n#makes a list of desired names\nselected_names = df[df['name'].isin(['Mary', 'Martha', 'Peter', 'Paul'])]\n\n#Builds plot\nfig3 = px.line(\n    selected_names,\n    x = \"year\",\n    y = \"Total\",\n    color = 'name',\n    title = 'The Usage of The Names Mary, Martha, Peter, and Paul over time'\n)\n\n#Set the range of x-axis to what the question asks for\nfig3.update_xaxes(\n    range = [1920, 2000]\n)\n\n#Renames x-axis, resize the title\nfig3.update_layout(\n    xaxis_title = \"Year\",\n    title_font = dict(size = 20)\n)\n\nfig3\n\n\n                                                \n\n\nAs you can see from the chart above, the different names are color coded for better readability. The name Mary was the most popular for a while, but it dropped very heavily after the year 1954.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#do-characters-in-popular-movies-effect-how-often-that-name-is-used",
    "href": "Projects/project1.html#do-characters-in-popular-movies-effect-how-often-that-name-is-used",
    "title": "Client Report - [The Usage Of Names Over Time]",
    "section": "Do Characters In Popular Movies Effect How Often That Name is Used?",
    "text": "Do Characters In Popular Movies Effect How Often That Name is Used?\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI decided to go with the name “Forrest” because of the movie “Forrest Gump”. What is interesting but not surprising, is the instant increase in the usage of the name in the year 1994, followed by an immediate decrease. Now, it is not like there were a lot of people named Forrest, but you can clearly see an increase in the name immediately when the movie was released. This shows a direct correlation between the year that the movie “Forrest Gump” came out, and the dramatic increase in the usage of the name Forrest.\n\n\nShow the code\n#Builds the Plot\nfig4 = px.line(\n    df.query('name == \"Forrest\"'),\n    x = 'year',\n    y = 'Total',\n    title = 'The usage of the Name Forest Over Time'\n)\n\n#Draws arrow over the year Forrest g=Gump came out\nfig4.add_annotation(\n    x = 1994,\n    y = max(df.query('name == \"Forrest\"')['Total']),\n    text = 'The year that the move \"Forrest Gump\" came out',\n    showarrow = True,\n    arrowhead = 1,\n    ax = -20,\n    ay = -40,\n    font = dict(size = 16),\n)\n\n#Renames x-axis and resizes the title\nfig4.update_layout(\n    xaxis_title = \"Year\",\n    title_font = dict(size = 20)\n)\n\nfig4\n\n\n                                                \n\n\n_The name Forrest isn’t the most popular name, but there is an obvious increase in the year 1994, the same year that the movie Forrest Gump was released.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Joey Kazmierski’s Resume",
    "section": "",
    "text": "datascience@byui.edu | Data Science Program"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Joey Kazmierski’s Resume",
    "section": "Education",
    "text": "Education\n2019-2023 Billings West High School, Billings, Montana\n\nHonors/AP Student\nStudent Athlete: Tennis and Lacrosse\n3.8 Cumulative GPA\nAll State Musician 4x for Trumpet\n\n2023 Brigham Young University, Rexburg, ID\n\n4.0 GPA\nExpected graduation 2027\nMajor in Mathematics with an Emphasis in Statistics"
  },
  {
    "objectID": "resume.html#service-and-work-history",
    "href": "resume.html#service-and-work-history",
    "title": "Joey Kazmierski’s Resume",
    "section": "Service and Work History",
    "text": "Service and Work History\n2021-2022 Game master, Billings Escape Room\n2022 Landscaper, Wedgewood Homes\n2023 Warehouse Worker, Amazon"
  }
]